import optuna
import xgboost as xgb
import numpy as np
import pandas as pd
import gc
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score

# Bizim modÃ¼ller
from src.data_loader import load_datasets
from src.preprocessing import merge_data
from src.feature_engineering import run_feature_engineering

def objective(trial, X, y):
    """
    Optuna'nÄ±n her denemede (trial) Ã§alÄ±ÅŸtÄ±racaÄŸÄ± fonksiyon.
    Burada rastgele parametreler seÃ§ilir ve model test edilir.
    """
    
    # 1. Hiperparametre Arama AlanÄ± (Search Space)
    # Optuna'ya diyoruz ki: "Bu aralÄ±klarda gez"
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 600),
        'max_depth': trial.suggest_int('max_depth', 3, 12),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
        # Sabit Parametreler
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'tree_method': 'hist', # HÄ±zlandÄ±rma iÃ§in
        'random_state': 42,
        'n_jobs': -1 # TÃ¼m iÅŸlemci Ã§ekirdeklerini kullan
    }

    # Dengesizlik ayarÄ±nÄ± ekle (scale_pos_weight)
    ratio = float(np.sum(y == 0)) / np.sum(y == 1)
    params['scale_pos_weight'] = ratio

    # 2. Veriyi BÃ¶l (Train / Validation)
    # Her denemede %20'lik kÄ±smÄ± ayÄ±rÄ±p test ediyoruz
    train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

    # 3. Modeli EÄŸit
    model = xgb.XGBClassifier(**params)
    model.fit(train_x, train_y)

    # 4. Skoru Hesapla
    preds = model.predict_proba(valid_x)[:, 1]
    auc = roc_auc_score(valid_y, preds)

    return auc

def run_optimization():
    print("ğŸš€ OPTUNA OPTÄ°MÄ°ZASYONU BAÅLIYOR...")
    print("="*40)

    # --- VERÄ° HAZIRLIÄI (Submission.py ile aynÄ± mantÄ±k) ---
    print("[1/4] Veriler yÃ¼kleniyor...")
    # Sadece Train verisi yeterli, optimizasyonu orada yapacaÄŸÄ±z
    df_trans, df_id = load_datasets('input/train_transaction.csv', 'input/train_identity.csv')
    df = merge_data(df_trans, df_id)
    
    del df_trans, df_id
    gc.collect()

    print("[2/4] Feature Engineering yapÄ±lÄ±yor...")
    df = run_feature_engineering(df)

    # Hedef ve Ã–zellikler
    y = df['isFraud']
    X = df.drop(['isFraud', 'TransactionID'], axis=1)

    del df
    gc.collect()

    # --- OPTUNA Ã‡ALIÅTIRMA ---
    print("\n[3/4] Robot Ã§alÄ±ÅŸmaya baÅŸladÄ± (Bu iÅŸlem zaman alabilir)...")
    
    # Study: Optuna'nÄ±n Ã§alÄ±ÅŸma defteri
    # direction='maximize' -> Ã‡Ã¼nkÃ¼ AUC skorunun yÃ¼ksek olmasÄ±nÄ± istiyoruz
    study = optuna.create_study(direction='maximize')
    
    # lambda fonksiyonu ile veriyi objective fonksiyonuna taÅŸÄ±yoruz
    study.optimize(lambda trial: objective(trial, X, y), n_trials=20) 

    # --- SONUÃ‡LAR ---
    print("\n" + "="*40)
    print("ğŸ† EN Ä°YÄ° SONUÃ‡LAR BULUNDU!")
    print(f"En YÃ¼ksek AUC Skoru: {study.best_value:.5f}")
    print("En Ä°yi Parametreler:")
    for key, value in study.best_params.items():
        print(f"  {key}: {value}")
    print("="*40)
    print("ğŸ‘‰ Åimdi bu parametreleri 'submission.py' dosyana kopyalayabilirsin!")

if __name__ == "__main__":
    run_optimization()