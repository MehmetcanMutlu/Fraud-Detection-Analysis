from src.data_loader import load_datasets
from src.preprocessing import merge_data
from src.feature_engineering import run_feature_engineering
import pandas as pd
import xgboost as xgb
import numpy as np
import gc

def main():
    print("ğŸš€ KAGGLE SUBMISSION MODU BAÅLATILIYOR (OPTUNA AYARLARI)")
    print("="*40)

    # 1. VERÄ°LERÄ° YÃœKLE
    print("1. AdÄ±m: Train ve Test verileri yÃ¼kleniyor...")
    try:
        train_trans, train_id = load_datasets('input/train_transaction.csv', 'input/train_identity.csv')
        test_trans, test_id = load_datasets('input/test_transaction.csv', 'input/test_identity.csv')
    except FileNotFoundError:
        print("âŒ HATA: Dosyalar bulunamadÄ±! Input klasÃ¶rÃ¼nÃ¼ kontrol et.")
        return

    # 2. BÄ°RLEÅTÄ°R (Merge)
    print("\n2. AdÄ±m: Tablolar birleÅŸtiriliyor...")
    train_df = merge_data(train_trans, train_id)
    test_df = merge_data(test_trans, test_id)
    
    # HafÄ±za temizliÄŸi
    del train_trans, train_id, test_trans, test_id
    gc.collect()

    # Data Leakage Ã–nlemi: Index Slicing iÃ§in uzunluÄŸu kaydet
    train_len = len(train_df)
    print(f"[BILGI] Train seti uzunluÄŸu kaydedildi: {train_len}")

    # Test setinde 'isFraud' sÃ¼tunu yok, hata vermesin diye geÃ§ici ekliyoruz
    test_df['isFraud'] = -1 

    # 3. TEK PARÃ‡A HALÄ°NE GETÄ°R (Concat)
    print("\n3. AdÄ±m: Feature Engineering iÃ§in birleÅŸtiriliyor...")
    full_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)
    
    del train_df, test_df
    gc.collect()

    # 4. FEATURE ENGINEERING
    # TÃ¼m veriyi (Train + Test) aynÄ± anda iÅŸliyoruz ki tutarlÄ± olsun
    full_df = run_feature_engineering(full_df)

    # 5. TEKRAR AYIR (Index Slicing)
    print("\n4. AdÄ±m: Veriler tekrar ayrÄ±lÄ±yor (Index Slicing)...")
    
    # 0'dan train_len'e kadar olanlar TRAIN
    train_df = full_df.iloc[:train_len]
    
    # train_len'den sonuna kadar olanlar TEST
    test_df = full_df.iloc[train_len:]
    
    # Test verisinden geÃ§ici isFraud ve ID'leri temizle
    test_ids = test_df['TransactionID']
    test_df = test_df.drop(['isFraud', 'TransactionID'], axis=1)
    
    del full_df
    gc.collect()

    # 6. MODEL EÄÄ°TÄ°MÄ° (SÃœPER AYARLAR Ä°LE)
    print("\n5. AdÄ±m: Model eÄŸitiliyor (Optuna ile optimize edildi)...")
    
    y = train_df['isFraud'].astype(int)
    X = train_df.drop(['isFraud', 'TransactionID'], axis=1)
    
    # Dengesizlik ayarÄ±
    ratio = float(np.sum(y == 0)) / np.sum(y == 1)
    print(f"[BILGI] Pos/Neg OranÄ± (scale_pos_weight): {ratio:.2f}")
    
    # ğŸ”¥ OPTUNA ROBOTUNUN BULDUÄU PARAMETRELER ğŸ”¥
    model = xgb.XGBClassifier(
        n_estimators=165,           # Robot buldu
        max_depth=12,               # Robot buldu (Derin Ã¶ÄŸrenme)
        learning_rate=0.190197,     # Robot buldu
        subsample=0.86821,          # Robot buldu
        colsample_bytree=0.98775,   # Robot buldu
        scale_pos_weight=ratio,     # Dengesizlik ayarÄ± (Sabit)
        random_state=42,
        tree_method='hist',         # HÄ±zlandÄ±rma
        eval_metric='auc'
    )
    
    model.fit(X, y, verbose=True)
    print("âœ… Model eÄŸitimi tamamlandÄ±.")

    # 7. TAHMÄ°N VE KAYIT
    print("\n6. AdÄ±m: Submission dosyasÄ± hazÄ±rlanÄ±yor...")
    
    # OlasÄ±lÄ±k tahmini (0-1 arasÄ±)
    preds = model.predict_proba(test_df)[:, 1]
    
    submission = pd.DataFrame({
        'TransactionID': test_ids,
        'isFraud': preds
    })
    
    submission.to_csv('submission.csv', index=False)
    print("\nğŸ‰ TEBRÄ°KLER! 'submission.csv' dosyasÄ± oluÅŸturuldu.")
    print("ğŸš€ Kaggle'a yÃ¼klemeye hazÄ±rsÄ±n! (Hedef: 0.92+ Public Score)")

if __name__ == "__main__":
    main()