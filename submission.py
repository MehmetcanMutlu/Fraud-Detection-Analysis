from src.data_loader import load_datasets
from src.preprocessing import merge_data
from src.feature_engineering import run_feature_engineering
import pandas as pd
import xgboost as xgb
import numpy as np
import gc

def main():
    print("ğŸš€ KAGGLE SUBMISSION MODU BAÅLATILIYOR")
    print("="*40)

    # 1. VERÄ°LERÄ° YÃœKLE
    print("1. AdÄ±m: Train ve Test verileri yÃ¼kleniyor...")
    try:
        train_trans, train_id = load_datasets('input/train_transaction.csv', 'input/train_identity.csv')
        test_trans, test_id = load_datasets('input/test_transaction.csv', 'input/test_identity.csv')
    except FileNotFoundError:
        print("âŒ HATA: Dosyalar bulunamadÄ±! Input klasÃ¶rÃ¼nÃ¼ kontrol et.")
        return

    # 2. BÄ°RLEÅTÄ°R (Merge)
    print("\n2. AdÄ±m: Tablolar birleÅŸtiriliyor...")
    train_df = merge_data(train_trans, train_id)
    test_df = merge_data(test_trans, test_id)
    
    # HafÄ±za temizliÄŸi
    del train_trans, train_id, test_trans, test_id
    gc.collect()

    # âš ï¸ KRÄ°TÄ°K NOKTA (HATAYI Ã‡Ã–ZEN KISIM)
    # Etiket (dataset_type) kullanmak yerine, train setinin uzunluÄŸunu kaydediyoruz.
    # Feature Engineering sonrasÄ± bu sayÄ±dan kesip ayÄ±racaÄŸÄ±z.
    train_len = len(train_df)
    print(f"[BILGI] Train seti uzunluÄŸu kaydedildi: {train_len}")

    # Test setinde 'isFraud' sÃ¼tunu yok, hata vermesin diye geÃ§ici olarak ekliyoruz.
    test_df['isFraud'] = -1 

    # 3. TEK PARÃ‡A HALÄ°NE GETÄ°R (Concat)
    print("\n3. AdÄ±m: Feature Engineering iÃ§in birleÅŸtiriliyor...")
    full_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)
    
    del train_df, test_df
    gc.collect()

    # 4. FEATURE ENGINEERING
    full_df = run_feature_engineering(full_df)

    # 5. TEKRAR AYIR (Index Slicing ile)
    print("\n4. AdÄ±m: Veriler tekrar ayrÄ±lÄ±yor (Index Slicing)...")
    
    # 0'dan train_len'e kadar olanlar TRAIN
    train_df = full_df.iloc[:train_len]
    
    # train_len'den sonuna kadar olanlar TEST
    test_df = full_df.iloc[train_len:]
    
    # Test verisinden geÃ§ici isFraud sÃ¼tununu atalÄ±m
    test_ids = test_df['TransactionID'] # ID'leri sakla
    test_df = test_df.drop(['isFraud', 'TransactionID'], axis=1) # Temizle
    
    del full_df
    gc.collect()

    # 6. MODEL EÄÄ°TÄ°MÄ°
    print("\n5. AdÄ±m: Model eÄŸitiliyor (Full Train Seti ile)...")
    
    y = train_df['isFraud'].astype(int)
    X = train_df.drop(['isFraud', 'TransactionID'], axis=1)
    
    # Dengesizlik ayarÄ±
    ratio = float(np.sum(y == 0)) / np.sum(y == 1)
    print(f"[BILGI] Pos/Neg OranÄ±: {ratio:.2f}")
    
    model = xgb.XGBClassifier(
        n_estimators=500,
        max_depth=10,
        learning_rate=0.05,
        scale_pos_weight=ratio,
        random_state=42,
        tree_method='hist'
    )
    
    model.fit(X, y, verbose=True)
    print("âœ… Model eÄŸitimi tamamlandÄ±.")

    # 7. TAHMÄ°N VE KAYIT
    print("\n6. AdÄ±m: Submission dosyasÄ± hazÄ±rlanÄ±yor...")
    
    preds = model.predict_proba(test_df)[:, 1]
    
    submission = pd.DataFrame({
        'TransactionID': test_ids,
        'isFraud': preds
    })
    
    submission.to_csv('submission.csv', index=False)
    print("\nğŸ‰ TEBRÄ°KLER! 'submission.csv' dosyasÄ± oluÅŸturuldu.")
    print("GitHub'a atmadan Ã¶nce Kaggle'a yÃ¼kleyip sÄ±ranÄ± gÃ¶rebilirsin!")

if __name__ == "__main__":
    main()