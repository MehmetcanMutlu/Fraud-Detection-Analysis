from src.data_loader import load_datasets
from src.preprocessing import merge_data
from src.feature_engineering import run_feature_engineering
import pandas as pd
import xgboost as xgb
import numpy as np
import gc

def main():
    print("ğŸš€ KAGGLE SUBMISSION MODU BAÅLATILIYOR")
    print("="*40)

    # 1. VERÄ°LERÄ° YÃœKLE (Train + Test)
    # input klasÃ¶rÃ¼nde test_transaction.csv ve test_identity.csv olduÄŸundan emin ol!
    print("1. AdÄ±m: Train ve Test verileri yÃ¼kleniyor...")
    try:
        train_trans, train_id = load_datasets('input/train_transaction.csv', 'input/train_identity.csv')
        test_trans, test_id = load_datasets('input/test_transaction.csv', 'input/test_identity.csv')
    except FileNotFoundError:
        print("âŒ HATA: Test dosyalarÄ± bulunamadÄ±! 'input' klasÃ¶rÃ¼ne test_transaction.csv ve test_identity.csv dosyalarÄ±nÄ± koymalÄ±sÄ±n.")
        return

    # 2. BÄ°RLEÅTÄ°R (Merge)
    print("\n2. AdÄ±m: Tablolar birleÅŸtiriliyor...")
    train_df = merge_data(train_trans, train_id)
    test_df = merge_data(test_trans, test_id)
    
    # RAM TemizliÄŸi
    del train_trans, train_id, test_trans, test_id
    gc.collect()

    # 3. KARIÅIKLIK OLMASIN DÄ°YE ETÄ°KETLEME
    train_df['dataset_type'] = 'train'
    test_df['dataset_type'] = 'test'
    test_df['isFraud'] = -1 # Test setinde cevaplar yok, geÃ§ici deÄŸer

    # 4. TEK PARÃ‡A HALÄ°NE GETÄ°R (Concat)
    print("\n3. AdÄ±m: Train ve Test setleri birleÅŸtiriliyor (Feature Engineering iÃ§in)...")
    full_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)
    
    del train_df, test_df
    gc.collect()

    # 5. FEATURE ENGINEERING (SayÄ±ya Ã‡evirme)
    # BurasÄ± biraz uzun sÃ¼rebilir (1 milyondan fazla satÄ±r)
    full_df = run_feature_engineering(full_df)

    # 6. TEKRAR AYIR
    print("\n4. AdÄ±m: Veriler tekrar Train/Test olarak ayrÄ±lÄ±yor...")
    train_df = full_df[full_df['dataset_type'] == 'train'].drop('dataset_type', axis=1)
    test_df = full_df[full_df['dataset_type'] == 'test'].drop(['dataset_type', 'isFraud'], axis=1)
    
    # ID'leri sakla (Kaggle istiyor)
    test_ids = test_df['TransactionID']
    
    del full_df
    gc.collect()

    # 7. MODEL EÄÄ°TÄ°MÄ° (Full Train Data ile)
    print("\n5. AdÄ±m: Model eÄŸitiliyor (Full Train Seti ile)...")
    
    y = train_df['isFraud'].astype(int)
    X = train_df.drop(['isFraud', 'TransactionID'], axis=1)
    
    # Dengesizlik ayarÄ±
    ratio = float(np.sum(y == 0)) / np.sum(y == 1)
    
    model = xgb.XGBClassifier(
        n_estimators=500,       # Daha gÃ¼Ã§lÃ¼ (500 aÄŸaÃ§)
        max_depth=10,
        learning_rate=0.05,
        scale_pos_weight=ratio,
        random_state=42,
        tree_method='hist'      # HÄ±zlandÄ±rma
    )
    
    model.fit(X, y, verbose=True)
    print("âœ… Model eÄŸitimi tamamlandÄ±.")

    # 8. TAHMÄ°N VE KAYIT
    print("\n6. AdÄ±m: Test seti Ã¼zerinde tahmin yapÄ±lÄ±yor...")
    X_test = test_df.drop('TransactionID', axis=1)
    
    # OlasÄ±lÄ±k tahmini al (0 ile 1 arasÄ±)
    preds = model.predict_proba(X_test)[:, 1] 
    
    submission = pd.DataFrame({
        'TransactionID': test_ids,
        'isFraud': preds
    })
    
    submission.to_csv('submission.csv', index=False)
    print("\nğŸ‰ TEBRÄ°KLER! 'submission.csv' dosyasÄ± oluÅŸturuldu.")
    print("Åimdi bu dosyayÄ± Kaggle'a yÃ¼kleyebilirsin!")

if __name__ == "__main__":
    main()